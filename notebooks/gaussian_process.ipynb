{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process in PyMC4\n",
    "\n",
    "### Theory\n",
    "\n",
    "Gaussian process are non-parametric models that define a distribution over a function where function itself is a random variable of some inputs $X$. They can be thought of as a distribution over infinite dimensions but computation can be done using finite resources. This property makes them useful for many spacial and temporal prediction tasks. A Gaussian Process prior is parameterized by a mean function and a covariance function. Given these parameters, a GP prior can be defined as\n",
    "\n",
    "$$f(x) \\sim \\mathcal{GP}\\left(\\mu(x), k(x, x')\\right)$$\n",
    "\n",
    "Given a prior and some new data $X^\\prime$, the conditional $P(f(X^\\prime) | f(X))$ can be evaluated as\n",
    "\n",
    "$$P(f(X^\\prime) | f(X)) = \\frac{P(f(X^\\prime), f(X))}{P(f(X))}$$\n",
    "\n",
    "This conditional can then be used to sample new points from the inferred function.\n",
    "\n",
    "### Implementation\n",
    "\n",
    "The implementation of Gaussian Process model is divided in three parts:\n",
    "\n",
    "1. Creating a mean function.\n",
    "2. Creating a covariance function.\n",
    "3. Creating a GP Model.\n",
    "\n",
    "The following tutorial shows how to create a GP Model in PyMC4 step-by-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing our libraries\n",
    "import sys\n",
    "# print(sys.path)\n",
    "sys.path.append(\"C:\\\\Users\\\\tirth\\\\Desktop\\\\INTERESTS\\\\PyMC4\")\n",
    "import pymc4 as pm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean functions\n",
    "\n",
    "The mean functions in PyMC4 are implemented using the following base class\n",
    "\n",
    "```python\n",
    "class Mean:\n",
    "    r\"\"\"Base Class for all the mean functions in GP.\"\"\"\n",
    "\n",
    "    def __init__(self, feature_ndims=1):\n",
    "        self.feature_ndims = feature_ndims\n",
    "\n",
    "    def __call__(self, X):\n",
    "        raise NotImplementedError(\"Your mean function should override this method\")\n",
    "\n",
    "    def __add__(self, mean2):\n",
    "        return MeanAdd(self, mean2)\n",
    "\n",
    "    def __mul__(self, mean2):\n",
    "        return MeanProd(self, mean2)\n",
    "```\n",
    "\n",
    "where `feature_ndims` are the rightmost dimentions of the input that will be absorbed during the computation. The `__call__` method is used to evaluate the mean function at some point $X$. The $X$ (input) can be a TensorFlow Tensor or a NumPy array. PyMC4 allows addition (or multiplication) of two mean function to yield a new mean function that is an instance of ``MeanAdd`` (or ``MeanProd``). You can create your own mean function just by inheriting the base class and implementing the method ``__call__``.\n",
    "\n",
    "The most common mean function used in GP models is the zero mean function that returns zero irrespective of the inputs. It can be implemented as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fn = pm.gp.mean.Zero(feature_ndims=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance Functions\n",
    "\n",
    "Covariance function try to approximate the covariance matrix of the modelled function. The base class used to implement covariance functions in PyMC4 is given below\n",
    "\n",
    "```python\n",
    "class Covariance:\n",
    "    r\"\"\"Base class of all Covariance functions for Gaussian Process\"\"\"\n",
    "\n",
    "    def __init__(self, feature_ndims, diag=False, **kwargs):\n",
    "        self.feature_ndims = feature_ndims\n",
    "        self.diag = diag\n",
    "        self._kernel = self._init_kernel(feature_ndims=self.feature_ndims, **kwargs)\n",
    "\n",
    "    @abstractmethod\n",
    "    def _init_kernel(self, feature_ndims, **kwargs):\n",
    "        raise NotImplementedError(\"Your Covariance class should override this method\")\n",
    "\n",
    "    def __call__(self, X1, X2, **kwargs):\n",
    "        if self.diag:\n",
    "            return tf.linalg.diag_part(self._kernel.apply(X1, X2, **kwargs))\n",
    "        else:\n",
    "            return self._kernel.matrix(X1, X2, **kwargs)\n",
    "\n",
    "    def evaluate_kernel(self, X1, X2, **kwargs):\n",
    "        ...\n",
    "\n",
    "    def __add__(self, cov2):\n",
    "        return CovarianceAdd(self, cov2)\n",
    "\n",
    "    def __mul__(self, cov2):\n",
    "        return CovarianceProd(self, cov2)\n",
    "```\n",
    "\n",
    "where ``_init_kernel`` is a method used to initialize the covariance function. This method should return a instance of covariance function that has ``matrix`` method to evaluate the covariance function and return a covariance matrix. Specifically, this method takes as input two tensors (or numpy arrays) of shape ``(batch_shape, n, features)`` and ``(batch_shape, m, features)`` and returns a covariance matrix of shape ``(batch_shape, n, m)``. This marix **must** be positive semi-definite. Meaning, $|C| > 0$ and $C = C^T$ where $C$ is the returned covariance matrix. You can optionally override ``evaluate_kernel`` method to evaluate the function at two specific points.\n",
    "\n",
    "There are many covariance functions that can be used to infer different functions but the most common one is the Radial Basis Function. This function can be implemented using the ``ExpQuad`` covariance function in PyMC4.\n",
    "\n",
    "$$k(x, x') = \\sigma^2 \\mathrm{exp}\\left[ -\\frac{(x - x')^2}{2 l^2} \\right]$$\n",
    "\n",
    "where $\\sigma$ = ``amplitude`` and $l$ = ``length_scale`` i.e. the inputs that RBF kernel in PyMC4 takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_fn = pm.gp.cov.ExpQuad(amplitude=1., length_scale=1., feature_ndims=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Gaussian Process\n",
    "\n",
    "The `gp.LatentGP` class is a direct implementation of a GP.  No additive noise is assumed.  It is called \"Latent\" because the underlying function values are treated as latent variables.  It has a `prior` method and a `conditional` method.  Given a mean and covariance function the function $f(x)$ is modeled as,\n",
    "    \n",
    "$$f(x) \\sim \\mathcal{GP}\\left(\\mu(x), k(x, x')\\right)$$\n",
    "\n",
    "Use the `prior` and `conditional` methods to actually construct random variables representing the unknown, or latent, function whose distribution is the GP prior or GP conditional.  This GP implementation can be used to implement regression on data that is not normally distributed. For more information on the `prior` and `conditional` methods, see their docstrings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = pm.gp.gp.LatentGP(mean_fn, cov_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "\n",
    "Having defined the mean function, covariance function and the GP model, `prior` and `conditional` methods can be used to sample new points from the prior and conditional respectively by creating a `pm.model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pm.model\n",
    "def gpmodel(gp, X, Xnew):\n",
    "    # Define a prior\n",
    "    f = yield gp.prior('f', X)\n",
    "    # Define a conditional oven new data points. Unlike PyMC3, the\n",
    "    # `given` dictionary is NOT optional.\n",
    "    cond = yield gp.conditional('cond', Xnew, given={'X': X, 'f': f})\n",
    "    return cond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs to the GP model\n",
    "\n",
    "Now, we are left with creating the inputs for our GP model. We will create random inputs `X` and `Xnew` with ``batch_shape=(2, 2)``, ``num_samples=10`` and ``feature_ndims=2`` of shape ``(2, 2)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The leftmost (2, 2) is the batch_shape. In the middle are the\n",
    "# actual data points and rightmost (2, 2) are the feature_ndims\n",
    "# that are going to be absorbed during the computation.\n",
    "X = np.random.randn(2, 2, 10, 2, 2)\n",
    "# Create new data points with 5 samples\n",
    "Xnew = np.random.randn(2, 2, 5, 2, 2)\n",
    "\n",
    "# We can now create a final function from which we can sample\n",
    "gp_model = gpmodel(gp, X, Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From c:\\Users\\tirth\\Desktop\\INTERESTS\\PyMC4\\env\\lib\\site-packages\\tensorflow\\python\\ops\\linalg\\linear_operator_lower_triangular.py:158: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\nInstructions for updating:\nDo not pass `graph_parents`.  They will  no longer be used.\n"
    }
   ],
   "source": [
    "samples = pm.sample(gp_model, num_samples=100, num_chains=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<xarray.Dataset>\nDimensions:             (chain: 3, draw: 100, gpmodel/cond_dim_0: 2, gpmodel/cond_dim_1: 2, gpmodel/cond_dim_2: 5, gpmodel/f_dim_0: 2, gpmodel/f_dim_1: 2, gpmodel/f_dim_2: 10)\nCoordinates:\n  * chain               (chain) int32 0 1 2\n  * draw                (draw) int32 0 1 2 3 4 5 6 7 ... 92 93 94 95 96 97 98 99\n  * gpmodel/f_dim_0     (gpmodel/f_dim_0) int32 0 1\n  * gpmodel/f_dim_1     (gpmodel/f_dim_1) int32 0 1\n  * gpmodel/f_dim_2     (gpmodel/f_dim_2) int32 0 1 2 3 4 5 6 7 8 9\n  * gpmodel/cond_dim_0  (gpmodel/cond_dim_0) int32 0 1\n  * gpmodel/cond_dim_1  (gpmodel/cond_dim_1) int32 0 1\n  * gpmodel/cond_dim_2  (gpmodel/cond_dim_2) int32 0 1 2 3 4\nData variables:\n    gpmodel/f           (chain, draw, gpmodel/f_dim_0, gpmodel/f_dim_1, gpmodel/f_dim_2) float32 0.38346636 ... 0.7068987\n    gpmodel/cond        (chain, draw, gpmodel/cond_dim_0, gpmodel/cond_dim_1, gpmodel/cond_dim_2) float32 -1.8316123 ... 1.1900791\nAttributes:\n    created_at:  2020-03-02T16:33:21.527284\n(3, 100, 2, 2, 10)\n(3, 100, 2, 2, 5)\n"
    }
   ],
   "source": [
    "print(samples.posterior)\n",
    "print(samples.posterior[\"gpmodel/f\"].shape)\n",
    "print(samples.posterior[\"gpmodel/cond\"].shape)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('env': venv)",
   "language": "python",
   "name": "python37364bitenvvenv9cd16de851e0485399f1b8891261ccaa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}